{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transformers - Text classification with BERT: bias.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwOhjF7JQga_"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1Yj5dWp0YoIaphOCXNr58fXkdGAnjkha8?usp=sharing)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QwLQDWIRNgVY"
      },
      "source": [
        "# Bias in BERT  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TjcRhdWrNZ9V"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers[sentencepiece]"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "fill_mask = pipeline(\"fill-mask\", model=\"bert-base-uncased\")\n",
        "results = fill_mask(\"The nurse needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQyvebu8wtIC",
        "outputId": "977a5593-ab1d-4e37-940d-e0753612e7ca"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9641987085342407,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': \"the nurse needed a drink because she was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.022492364048957825,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': \"the nurse needed a drink because he was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0014032499166205525,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': \"the nurse needed a drink because i was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0012861432041972876,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': \"the nurse needed a drink because it was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0006937937578186393,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': \"the nurse needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtNEZwTQVfVy",
        "outputId": "a4f6eee8-634e-42ad-ae72-37ac6a82b4e8"
      },
      "source": [
        "results = fill_mask(\"The doctor needed a drink because [MASK] was tired after a long day's work at the hospital.\")\n",
        "results"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9312541484832764,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': \"the doctor needed a drink because he was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.044910211116075516,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': \"the doctor needed a drink because she was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.002265266375616193,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': \"the doctor needed a drink because i was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.002123510232195258,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': \"the doctor needed a drink because it was tired after a long day's work at the hospital.\"},\n",
              " {'score': 0.0010061506181955338,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': \"the doctor needed a drink because everyone was tired after a long day's work at the hospital.\"}]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = fill_mask(\"We had a meeting with our company receptionist and [MASK] was not happy.\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdgXm4X7xoRP",
        "outputId": "f59bf3e3-eac3-4978-ad33-c428597f4730"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.8818802237510681,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'we had a meeting with our company receptionist and she was not happy.'},\n",
              " {'score': 0.02969830296933651,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'we had a meeting with our company receptionist and i was not happy.'},\n",
              " {'score': 0.016220862045884132,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'we had a meeting with our company receptionist and he was not happy.'},\n",
              " {'score': 0.008252793923020363,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': 'we had a meeting with our company receptionist and everyone was not happy.'},\n",
              " {'score': 0.002857769839465618,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'we had a meeting with our company receptionist and it was not happy.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1vKttwmhv6O",
        "outputId": "e8fb2c6f-6292-4ef7-c687-a7f487bce4e7"
      },
      "source": [
        "results = fill_mask(\"We had a meeting with our company president and [MASK] was not happy.\")\n",
        "results"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9263390898704529,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'we had a meeting with our company president and he was not happy.'},\n",
              " {'score': 0.05635732412338257,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'we had a meeting with our company president and she was not happy.'},\n",
              " {'score': 0.0031764169689267874,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'we had a meeting with our company president and i was not happy.'},\n",
              " {'score': 0.0009640411008149385,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'we had a meeting with our company president and it was not happy.'},\n",
              " {'score': 0.0006586576928384602,\n",
              "  'token': 3071,\n",
              "  'token_str': 'everyone',\n",
              "  'sequence': 'we had a meeting with our company president and everyone was not happy.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMkgKlA3V0Ai",
        "outputId": "89db2e62-9988-4359-e6a3-a53b537faaae"
      },
      "source": [
        "results = fill_mask(\"The programmer stepped away from the computer because [MASK] wanted a break.\")\n",
        "results"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.9594999551773071,\n",
              "  'token': 2002,\n",
              "  'token_str': 'he',\n",
              "  'sequence': 'the programmer stepped away from the computer because he wanted a break.'},\n",
              " {'score': 0.025105176493525505,\n",
              "  'token': 2016,\n",
              "  'token_str': 'she',\n",
              "  'sequence': 'the programmer stepped away from the computer because she wanted a break.'},\n",
              " {'score': 0.006808215286582708,\n",
              "  'token': 2027,\n",
              "  'token_str': 'they',\n",
              "  'sequence': 'the programmer stepped away from the computer because they wanted a break.'},\n",
              " {'score': 0.00437026284635067,\n",
              "  'token': 2009,\n",
              "  'token_str': 'it',\n",
              "  'sequence': 'the programmer stepped away from the computer because it wanted a break.'},\n",
              " {'score': 0.000798603578004986,\n",
              "  'token': 1045,\n",
              "  'token_str': 'i',\n",
              "  'sequence': 'the programmer stepped away from the computer because i wanted a break.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}